{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of EIP_P2S2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nrajmalwar/Python/blob/master/Session%202/Phase_2_Session_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aStez58HnlMM",
        "colab_type": "text"
      },
      "source": [
        "# Import Classes and Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcr-BLNEng4e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c03e0b28-6cbe-43a5-a03d-7992c9bb7fef"
      },
      "source": [
        "import sys\n",
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FbRFX7IlK-p",
        "colab_type": "text"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHyCqBxVoJc_",
        "colab_type": "code",
        "outputId": "feb04775-3851-40b2-d519-3afaf0df7726",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# load ascii text and covert to lowercase\n",
        "filename = \"wonderland.txt\"\n",
        "raw_text = open(filename, mode='r', encoding='utf-8-sig').read()\n",
        "\n",
        "raw_text = raw_text.lower()\n",
        "\n",
        "len(raw_text)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "144430"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqaXeA3Eo1So",
        "colab_type": "code",
        "outputId": "a29011cb-e794-4b60-d03a-321d72037a72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# data cleanup - remove punctuations from the text\n",
        "import string\n",
        "raw_text = raw_text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "len(raw_text)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "136110"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5z_yV9Nmy1c",
        "colab_type": "code",
        "outputId": "5b03545c-ea75-48f5-e413-fb6d4b880ea0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        }
      },
      "source": [
        "# Print first 1000 characters\n",
        "print(raw_text[0:1000])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "alices adventures in wonderland\n",
            "\n",
            "lewis carroll\n",
            "\n",
            "the millennium fulcrum edition 30\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "chapter i down the rabbithole\n",
            "\n",
            "alice was beginning to get very tired of sitting by her sister on the\n",
            "bank and of having nothing to do once or twice she had peeped into the\n",
            "book her sister was reading but it had no pictures or conversations in\n",
            "it and what is the use of a book thought alice without pictures or\n",
            "conversations\n",
            "\n",
            "so she was considering in her own mind as well as she could for the\n",
            "hot day made her feel very sleepy and stupid whether the pleasure\n",
            "of making a daisychain would be worth the trouble of getting up and\n",
            "picking the daisies when suddenly a white rabbit with pink eyes ran\n",
            "close by her\n",
            "\n",
            "there was nothing so very remarkable in that nor did alice think it so\n",
            "very much out of the way to hear the rabbit say to itself oh dear\n",
            "oh dear i shall be late when she thought it over afterwards it\n",
            "occurred to her that she ought to have wondered at this but at the time\n",
            "it all seemed quite natural but w\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0aV0X2boisO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create mapping of unique chars to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GltFnnJupXal",
        "colab_type": "code",
        "outputId": "3fb9df17-59b4-4aac-fcbd-87686fdba191",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print(\"Total Characters: \", n_chars)\n",
        "print(\"Total Vocab: \", n_vocab)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  136110\n",
            "Total Vocab:  30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjS9_fwyoLf1",
        "colab_type": "code",
        "outputId": "f2435f3a-1b24-4705-f1d4-56c796835b75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        }
      },
      "source": [
        "char_to_int"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " '0': 2,\n",
              " '3': 3,\n",
              " 'a': 4,\n",
              " 'b': 5,\n",
              " 'c': 6,\n",
              " 'd': 7,\n",
              " 'e': 8,\n",
              " 'f': 9,\n",
              " 'g': 10,\n",
              " 'h': 11,\n",
              " 'i': 12,\n",
              " 'j': 13,\n",
              " 'k': 14,\n",
              " 'l': 15,\n",
              " 'm': 16,\n",
              " 'n': 17,\n",
              " 'o': 18,\n",
              " 'p': 19,\n",
              " 'q': 20,\n",
              " 'r': 21,\n",
              " 's': 22,\n",
              " 't': 23,\n",
              " 'u': 24,\n",
              " 'v': 25,\n",
              " 'w': 26,\n",
              " 'x': 27,\n",
              " 'y': 28,\n",
              " 'z': 29}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d4yiYuPVJMq",
        "colab_type": "text"
      },
      "source": [
        "# Use Padded Sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSb69HJCKJnf",
        "colab_type": "code",
        "outputId": "da94d159-b1a4-4bbc-fdc8-ce2631306f9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "\n",
        "# Use a sequence length of 100\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "count = 0\n",
        "input_seq = []\n",
        "\n",
        "# Run a for loop to fetch each sequence of length 100\n",
        "for i in range(0, n_chars, seq_length):\n",
        "  seq_in = raw_text[i:i + seq_length]\n",
        "  \n",
        "  # # Run through the entire sequence\n",
        "  for j in range(0, len(seq_in)-1):\n",
        "    count += 1\n",
        "    \n",
        "    # Extract a sub-sequence from length 1 to 100\n",
        "    in_seq = seq_in[:j+1]\n",
        "    out_seq = seq_in[j+1]\n",
        "    \n",
        "    # Append the sub-sequences together\n",
        "    input_seq.append([char_to_int[char] for char in in_seq])\n",
        "    dataY.append(char_to_int[out_seq])\n",
        "\n",
        "# Pad all the sequences to length 100, use pre-padding    \n",
        "dataX = numpy.array(pad_sequences(input_seq, maxlen=seq_length, padding='pre')) \n",
        "\n",
        "n_patterns = len(dataX)\n",
        "print(\"Total Patterns: \", n_patterns)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns:  134748\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1u4ytNZX32a",
        "colab_type": "code",
        "outputId": "0e39893e-b2c5-418b-c786-a005b179fcba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(dataY)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "134748"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LO4d0CIsXI5z",
        "colab_type": "code",
        "outputId": "90cf93c7-51cf-474d-c3bc-251587a82623",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(dataX)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "134748"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwmbrEehWqJS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "outputId": "a3831a9e-87a2-47bc-9342-b71818b77292"
      },
      "source": [
        "dataX[:5]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  4],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  4, 15],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  4, 15, 12],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         4, 15, 12,  6],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  4,\n",
              "        15, 12,  6,  8]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFGkh8c3H9dN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSQepl_-IKuK",
        "colab_type": "text"
      },
      "source": [
        "# LSTM Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQpo-E8JIMX3",
        "colab_type": "code",
        "outputId": "d522ad1f-6771-423a-8048-02b45ba84817",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "# define the LSTM model\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Add dropout of 0.1 to the input layer\n",
        "model.add(Dropout(0.1))\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "\n",
        "model.add(Dropout(0.1))\n",
        "model.add(LSTM(256))\n",
        "\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0727 14:21:51.789352 139738329945984 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0727 14:21:51.806673 139738329945984 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CT8Soul9VEP_",
        "colab_type": "text"
      },
      "source": [
        "# Model Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mcJBBvGIgF_",
        "colab_type": "code",
        "outputId": "e7b68fc9-c8e3-4462-8b88-a5c0e5e8892f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Mount Google Drive to save the model\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Use ModelCheckpoint\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "checkpoint = ModelCheckpoint('/content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5', monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PevoMR_-vyx9",
        "colab_type": "text"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iCr4HyDImcC",
        "colab_type": "code",
        "outputId": "8ab7aebf-6c9c-4c65-f93c-9ecb9daccf8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X, y, epochs=50, batch_size=256, callbacks=callbacks_list)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0727 14:21:51.838175 139738329945984 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0727 14:21:51.841794 139738329945984 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0727 14:21:51.855834 139738329945984 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0727 14:21:51.870910 139738329945984 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0727 14:21:52.428807 139738329945984 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0727 14:21:52.539203 139738329945984 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "134748/134748 [==============================] - 138s 1ms/step - loss: 2.8374\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.83738, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 2/50\n",
            "134748/134748 [==============================] - 137s 1ms/step - loss: 2.6536\n",
            "\n",
            "Epoch 00002: loss improved from 2.83738 to 2.65355, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 3/50\n",
            "134748/134748 [==============================] - 137s 1ms/step - loss: 2.4774\n",
            "\n",
            "Epoch 00003: loss improved from 2.65355 to 2.47743, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 4/50\n",
            "134748/134748 [==============================] - 137s 1ms/step - loss: 2.3342\n",
            "\n",
            "Epoch 00004: loss improved from 2.47743 to 2.33416, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 5/50\n",
            "134748/134748 [==============================] - 137s 1ms/step - loss: 2.2327\n",
            "\n",
            "Epoch 00005: loss improved from 2.33416 to 2.23271, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 6/50\n",
            "134748/134748 [==============================] - 136s 1ms/step - loss: 2.1580\n",
            "\n",
            "Epoch 00006: loss improved from 2.23271 to 2.15804, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 7/50\n",
            "134748/134748 [==============================] - 137s 1ms/step - loss: 2.1172\n",
            "\n",
            "Epoch 00007: loss improved from 2.15804 to 2.11723, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 8/50\n",
            "134748/134748 [==============================] - 137s 1ms/step - loss: 2.0530\n",
            "\n",
            "Epoch 00008: loss improved from 2.11723 to 2.05300, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 9/50\n",
            "134748/134748 [==============================] - 137s 1ms/step - loss: 2.0077\n",
            "\n",
            "Epoch 00009: loss improved from 2.05300 to 2.00770, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 10/50\n",
            "134748/134748 [==============================] - 136s 1ms/step - loss: 1.9735\n",
            "\n",
            "Epoch 00010: loss improved from 2.00770 to 1.97354, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 11/50\n",
            "134748/134748 [==============================] - 136s 1ms/step - loss: 1.9422\n",
            "\n",
            "Epoch 00011: loss improved from 1.97354 to 1.94223, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 12/50\n",
            "134748/134748 [==============================] - 137s 1ms/step - loss: 1.9105\n",
            "\n",
            "Epoch 00012: loss improved from 1.94223 to 1.91053, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 13/50\n",
            "134748/134748 [==============================] - 136s 1ms/step - loss: 1.8878\n",
            "\n",
            "Epoch 00013: loss improved from 1.91053 to 1.88780, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 14/50\n",
            "134748/134748 [==============================] - 137s 1ms/step - loss: 1.8627\n",
            "\n",
            "Epoch 00014: loss improved from 1.88780 to 1.86274, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 15/50\n",
            "134748/134748 [==============================] - 136s 1ms/step - loss: 1.8433\n",
            "\n",
            "Epoch 00015: loss improved from 1.86274 to 1.84328, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 16/50\n",
            "134748/134748 [==============================] - 136s 1ms/step - loss: 1.8243\n",
            "\n",
            "Epoch 00016: loss improved from 1.84328 to 1.82426, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 17/50\n",
            "134748/134748 [==============================] - 136s 1ms/step - loss: 1.8070\n",
            "\n",
            "Epoch 00017: loss improved from 1.82426 to 1.80698, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 18/50\n",
            "134748/134748 [==============================] - 136s 1ms/step - loss: 1.7866\n",
            "\n",
            "Epoch 00018: loss improved from 1.80698 to 1.78658, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 19/50\n",
            "134748/134748 [==============================] - 136s 1ms/step - loss: 1.7701\n",
            "\n",
            "Epoch 00019: loss improved from 1.78658 to 1.77014, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 20/50\n",
            "134748/134748 [==============================] - 136s 1ms/step - loss: 1.7576\n",
            "\n",
            "Epoch 00020: loss improved from 1.77014 to 1.75760, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 21/50\n",
            "134748/134748 [==============================] - 136s 1ms/step - loss: 1.7460\n",
            "\n",
            "Epoch 00021: loss improved from 1.75760 to 1.74599, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 22/50\n",
            "134748/134748 [==============================] - 135s 1ms/step - loss: 1.7343\n",
            "\n",
            "Epoch 00022: loss improved from 1.74599 to 1.73435, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 23/50\n",
            "134748/134748 [==============================] - 136s 1ms/step - loss: 1.7159\n",
            "\n",
            "Epoch 00023: loss improved from 1.73435 to 1.71591, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 24/50\n",
            "134748/134748 [==============================] - 135s 1ms/step - loss: 1.7049\n",
            "\n",
            "Epoch 00024: loss improved from 1.71591 to 1.70490, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 25/50\n",
            "134748/134748 [==============================] - 136s 1ms/step - loss: 1.6954\n",
            "\n",
            "Epoch 00025: loss improved from 1.70490 to 1.69544, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 26/50\n",
            "134748/134748 [==============================] - 136s 1ms/step - loss: 1.6847\n",
            "\n",
            "Epoch 00026: loss improved from 1.69544 to 1.68474, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 27/50\n",
            "134748/134748 [==============================] - 135s 1ms/step - loss: 1.6755\n",
            "\n",
            "Epoch 00027: loss improved from 1.68474 to 1.67546, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 28/50\n",
            "134748/134748 [==============================] - 134s 997us/step - loss: 1.6643\n",
            "\n",
            "Epoch 00028: loss improved from 1.67546 to 1.66427, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 29/50\n",
            "134748/134748 [==============================] - 134s 994us/step - loss: 1.6539\n",
            "\n",
            "Epoch 00029: loss improved from 1.66427 to 1.65389, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 30/50\n",
            "134748/134748 [==============================] - 135s 999us/step - loss: 1.6472\n",
            "\n",
            "Epoch 00030: loss improved from 1.65389 to 1.64719, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 31/50\n",
            "134748/134748 [==============================] - 134s 993us/step - loss: 1.6392\n",
            "\n",
            "Epoch 00031: loss improved from 1.64719 to 1.63918, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 32/50\n",
            "134748/134748 [==============================] - 135s 999us/step - loss: 1.6287\n",
            "\n",
            "Epoch 00032: loss improved from 1.63918 to 1.62872, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 33/50\n",
            "134748/134748 [==============================] - 134s 992us/step - loss: 1.6248\n",
            "\n",
            "Epoch 00033: loss improved from 1.62872 to 1.62482, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 34/50\n",
            "134748/134748 [==============================] - 134s 997us/step - loss: 1.6077\n",
            "\n",
            "Epoch 00034: loss improved from 1.62482 to 1.60772, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 35/50\n",
            "134748/134748 [==============================] - 137s 1ms/step - loss: 1.6022\n",
            "\n",
            "Epoch 00035: loss improved from 1.60772 to 1.60218, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 36/50\n",
            "134748/134748 [==============================] - 138s 1ms/step - loss: 1.5955\n",
            "\n",
            "Epoch 00036: loss improved from 1.60218 to 1.59553, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 37/50\n",
            "134748/134748 [==============================] - 137s 1ms/step - loss: 1.5878\n",
            "\n",
            "Epoch 00037: loss improved from 1.59553 to 1.58785, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 38/50\n",
            "134748/134748 [==============================] - 136s 1ms/step - loss: 1.5816\n",
            "\n",
            "Epoch 00038: loss improved from 1.58785 to 1.58158, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 39/50\n",
            "134748/134748 [==============================] - 137s 1ms/step - loss: 1.5739\n",
            "\n",
            "Epoch 00039: loss improved from 1.58158 to 1.57388, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 40/50\n",
            "134748/134748 [==============================] - 136s 1ms/step - loss: 1.5658\n",
            "\n",
            "Epoch 00040: loss improved from 1.57388 to 1.56580, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 41/50\n",
            "134748/134748 [==============================] - 137s 1ms/step - loss: 1.5599\n",
            "\n",
            "Epoch 00041: loss improved from 1.56580 to 1.55992, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 42/50\n",
            "134748/134748 [==============================] - 136s 1ms/step - loss: 1.5532\n",
            "\n",
            "Epoch 00042: loss improved from 1.55992 to 1.55324, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 43/50\n",
            "134748/134748 [==============================] - 136s 1ms/step - loss: 1.5490\n",
            "\n",
            "Epoch 00043: loss improved from 1.55324 to 1.54903, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 44/50\n",
            "134748/134748 [==============================] - 136s 1ms/step - loss: 1.5426\n",
            "\n",
            "Epoch 00044: loss improved from 1.54903 to 1.54258, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 45/50\n",
            "134748/134748 [==============================] - 135s 1ms/step - loss: 1.5400\n",
            "\n",
            "Epoch 00045: loss improved from 1.54258 to 1.53998, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 46/50\n",
            "134748/134748 [==============================] - 136s 1ms/step - loss: 1.5310\n",
            "\n",
            "Epoch 00046: loss improved from 1.53998 to 1.53100, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 47/50\n",
            "134748/134748 [==============================] - 135s 1ms/step - loss: 1.5273\n",
            "\n",
            "Epoch 00047: loss improved from 1.53100 to 1.52733, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 48/50\n",
            "134748/134748 [==============================] - 136s 1ms/step - loss: 1.5209\n",
            "\n",
            "Epoch 00048: loss improved from 1.52733 to 1.52090, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 49/50\n",
            "134748/134748 [==============================] - 135s 1ms/step - loss: 1.5169\n",
            "\n",
            "Epoch 00049: loss improved from 1.52090 to 1.51690, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n",
            "Epoch 50/50\n",
            "134748/134748 [==============================] - 136s 1ms/step - loss: 1.5125\n",
            "\n",
            "Epoch 00050: loss improved from 1.51690 to 1.51246, saving model to /content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f173a5c3c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQ58rm4zt7Cb",
        "colab_type": "text"
      },
      "source": [
        "# Generate Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3dZIMiOt5gi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the network weights\n",
        "filename = '/content/drive/My Drive/Colab Notebooks/EIP_P2S2.hdf5'\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sns8qG8TuKB8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiCTiUPDUIpN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "17935f0c-efbc-432f-b315-545bab692018"
      },
      "source": [
        "# pick a random seed\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = list(dataX[start])\n",
        "print(\"Seed:\")\n",
        "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "\n",
        "# generate characters\n",
        "for i in range(500):\n",
        "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = numpy.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in_2 = [int_to_char[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print(\"\\nDone.\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed:\n",
            "\" \n",
            "\n",
            "\n",
            "aving nothing to do once or twice she had peeped into the\n",
            "book her sister was reading but it had  \"\n",
            "tatted tather anice anlce anlce anl rveer toanl anice anl e mike a tueenisg taid toeakdd tuite a cooverattoalisg taid toeakdd tuite a cooverattoalisg taid toeakdd tuite a cooverattoalisg taid toeakdd tuite a cooverattoalisg taid toeakdd tuite a cooverattoalisg taid toeakdd tuite a cooverattoalisg taid toeakdd tuite a cooverattoalisg taid toeakdd tuite a cooverattoalisg taid toeakdd tuite a cooverattoalisg taid toeakdd tuite a cooverattoalisg taid toeakdd tuite a cooverattoalisg taid toeakdd tuit\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}